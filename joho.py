import streamlit as st
import pandas as pd
import numpy as np
import time
import os
import re
import math
import html
import json
import google.generativeai as genai
import altair as alt
from janome.tokenizer import Tokenizer

# ãƒ¢ãƒ‡ãƒ«è¨­å®š
MODEL_NAME = "gemini-2.5-flash-preview-09-2025"

# å®‰å…¨æ€§è¨­å®šï¼ˆç‰©èªåˆ†æã§ãƒ–ãƒ­ãƒƒã‚¯ã•ã‚Œãªã„ã‚ˆã†ã«ç·©å’Œï¼‰
SAFETY_SETTINGS = [
    {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
]

# =========================================================
# 0. ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š & CSS
# =========================================================
st.set_page_config(page_title="EmoTrace - Narrative & Emotion", layout="wide")

st.markdown("""
<style>
    /* ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚¶ã‚¤ãƒ³ */
    body {
        font-family: "Helvetica Neue", Arial, "Hiragino Kaku Gothic ProN", "Hiragino Sans", Meiryo, sans-serif;
        background-color: #FDFDFD; color: #222;
    }
    h1 {
        color: #2C3E50;
        font-weight: 700; letter-spacing: -0.5px; margin-bottom: 0.5rem;
        border-bottom: 2px solid #eee; padding-bottom: 10px;
    }
    
    /* ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³è¡¨ç¤º */
    .timeline-container { position: relative; padding: 20px 0; }
    .timeline-container::before { content: ''; position: absolute; top: 0; bottom: 0; left: 90px; width: 1px; background: #ddd; }
    
    .timeline-item { position: relative; margin-bottom: 24px; display: flex; align-items: flex-start; }
    .timeline-time { width: 80px; text-align: right; padding-right: 20px; font-family: 'Courier New', monospace; font-weight: bold; color: #666; font-size: 0.85rem; padding-top: 4px; }
    .timeline-marker { position: absolute; left: 86px; width: 9px; height: 9px; border-radius: 50%; background: #FFF; border: 2px solid #888; z-index: 1; margin-top: 6px; }
    .timeline-content { flex: 1; margin-left: 20px; background: #FFF; border-radius: 4px; padding: 12px 16px; border: 1px solid #eee; border-left-width: 4px; color: #333; }
    
    .marker-pos { border-color: #2a9d8f; background: #2a9d8f; } .border-pos { border-left-color: #2a9d8f; }
    .marker-neg { border-color: #e76f51; background: #e76f51; } .border-neg { border-left-color: #e76f51; }
    
    /* ãƒãƒ£ãƒƒãƒˆã‚¨ãƒªã‚¢ */
    .chat-container { border-top: 1px solid #eee; padding-top: 20px; margin-top: 30px; }
</style>
""", unsafe_allow_html=True)

# =========================================================
# 1. Janome & è¾æ›¸ãƒ­ã‚¸ãƒƒã‚¯
# =========================================================

NEGATION_WORDS = ['ãªã„', 'ã¬', 'ãš', 'ã‚“', 'ã¾ã„']
ADVERSATIVE_WORDS = ['ã—ã‹ã—', 'ã§ã‚‚', 'ã ãŒ', 'ã‘ã‚Œã©', 'ã‘ã©ã‚‚', 'ã¨ã“ã‚ãŒ']
COMPOUND_RULES = {
    ('å…¨ã', 'è‰¯ã„'): 0.0, ('éå¸¸ã«', 'è‰¯ã„'): 1.2, ('ã¨ã¦ã‚‚', 'è‰¯ã„'): 1.2,
    ('ã™ã”ã', 'è‰¯ã„'): 1.2, ('ã‚ã¾ã‚Š', 'è‰¯ã„'): 0.2, ('å…¨ç„¶', 'è‰¯ã„'): 1.5,
}

@st.cache_resource
def get_tokenizer():
    return Tokenizer()

@st.cache_resource
def load_sentiment_dictionary():
    dict_files = [
        {'name': 'pn_ja.dic', 'enc': 'shift-jis', 'sep': ':', 'cols': [0, 3]},
        {'name': 'wago.121808.pn', 'enc': 'utf-8', 'sep': '\t', 'cols': [1, 0]},
        {'name': 'pn.csv.m3.120408.trim', 'enc': 'utf-8', 'sep': '\t', 'cols': [0, 1]}
    ]
    dic_data = {}
    loaded_files = []
    
    for d in dict_files:
        path = d['name']
        if not os.path.exists(path):
            path = os.path.join('dic', d['name'])
        
        if os.path.exists(path):
            try:
                df = pd.read_csv(path, encoding=d['enc'], sep=d['sep'], header=None, on_bad_lines='skip')
                term_col = d['cols'][0]
                score_col = d['cols'][1]
                if len(df.columns) > max(term_col, score_col):
                    for _, row in df.iterrows():
                        term = str(row[term_col]).strip()
                        val = row[score_col]
                        score = 0.0
                        if isinstance(val, (int, float)): score = float(val)
                        elif isinstance(val, str):
                            val = val.lower().strip()
                            if val in ['p', 'pos', 'positive']: score = 1.0
                            elif val in ['n', 'neg', 'negative']: score = -1.0
                            elif val in ['e', 'neu', 'neutral']: score = 0.0
                            else:
                                try: score = float(val)
                                except: pass
                        if score != 0.0: dic_data[term] = score
                    loaded_files.append(d['name'])
            except: pass
    if not dic_data:
        dic_data = {'è‰¯ã„': 1.0, 'æ‚ªã„': -1.0, 'å¥½ã': 1.0, 'å«Œã„': -1.0, 'æ¥½ã—ã„': 0.9, 'é€€å±ˆ': -0.9}
    return dic_data, loaded_files

SENTIMENT_DICT, LOADED_DICTS = load_sentiment_dictionary()

def analyze_sentiment_advanced(text):
    if not text: return 0.0, []
    text_norm = text.replace("ã‚ã‚Šã¾ã›ã‚“", "ãªã„ã§ã™")
    t = get_tokenizer()
    tokens = list(t.tokenize(text_norm))
    matched_scores = []
    calc_log = [] 
    current_boost = 1.0
    
    i = 0
    while i < len(tokens):
        token = tokens[i]
        base_form = token.base_form
        pos_part = token.part_of_speech.split(',')
        pos = pos_part[0]
        sub_pos = pos_part[1] if len(pos_part) > 1 else ""
        
        if (pos == 'æ¥ç¶šè©' and base_form in ADVERSATIVE_WORDS) or \
           (pos == 'åŠ©è©' and sub_pos == 'æ¥ç¶šåŠ©è©' and base_form in ['ãŒ', 'ã‘ã©', 'ã‘ã‚Œã©', 'ã‘ã‚Œã©ã‚‚']):
            current_boost = 1.5
            calc_log.append({'term': base_form, 'score': 0, 'reason': 'é€†æ¥(x1.5)', 'weight': 0, 'boost': current_boost})
        
        current_score = 0.0
        found_sentiment = False
        reason = ""
        matched_term = base_form
        
        if pos in ['å½¢å®¹è©', 'å‹•è©', 'åè©']:
            for j in range(1, 5):
                if i - j >= 0:
                    prev_base = tokens[i-j].base_form
                    if (prev_base, base_form) in COMPOUND_RULES:
                        current_score = COMPOUND_RULES[(prev_base, base_form)]
                        found_sentiment = True
                        matched_term = f"{prev_base}+{base_form}"
                        reason = "é€£èª"
                        break
        
        if not found_sentiment and base_form in SENTIMENT_DICT:
            if pos in ['åè©', 'å‹•è©', 'å½¢å®¹è©', 'å‰¯è©', 'é€£ä½“è©', 'æ„Ÿå‹•è©']:
                current_score = float(SENTIMENT_DICT[base_form])
                found_sentiment = True
                reason = "è¾æ›¸"
        
        if found_sentiment:
            negated = False
            neg_term = ""
            for k in range(1, 4):
                if i + k < len(tokens):
                    nb = tokens[i+k].base_form
                    if nb in NEGATION_WORDS: negated = True; neg_term=nb; break
                    if nb in ['ã€‚', 'ã€', 'ï¼', 'EOS']: break
            if negated:
                current_score *= -1.0
                reason += f" â¡ å¦å®šã€Œ{neg_term}ã€"
            
            final_weight = 1.0 * current_boost
            matched_scores.append({'score': current_score, 'weight': final_weight})
            calc_log.append({'term': matched_term, 'score': current_score, 'reason': reason, 'weight': final_weight, 'boost': current_boost})
            
        i += 1
        
    if not matched_scores: return 0.0, calc_log
    weighted_sum = sum(item['score'] * item['weight'] for item in matched_scores)
    total_weight = sum(item['weight'] for item in matched_scores)
    final_score = weighted_sum / total_weight if total_weight > 0 else 0.0
    return max(-1.0, min(1.0, final_score)), calc_log

# =========================================================
# 2. ã‚¹ãƒ†ãƒ¼ãƒˆ & AIçŸ¥è­˜ãƒ™ãƒ¼ã‚¹ (è©³ç´°ç‰ˆå¾©å…ƒ)
# =========================================================

if 'status' not in st.session_state: st.session_state.status = 'ready'
if 'start_time' not in st.session_state: st.session_state.start_time = None
if 'elapsed_offset' not in st.session_state: st.session_state.elapsed_offset = 0.0
if 'notes' not in st.session_state: st.session_state.notes = [] 
if 'analyzed_notes' not in st.session_state: st.session_state.analyzed_notes = [] 
if 'gemini_api_key' not in st.session_state: st.session_state.gemini_api_key = ""
if 'chat_history' not in st.session_state: st.session_state.chat_history = []
if 'chat_initialized' not in st.session_state: st.session_state.chat_initialized = False
if 'compare_data' not in st.session_state: st.session_state.compare_data = None
if 'compare_title' not in st.session_state: st.session_state.compare_title = ""

# ãƒ¦ãƒ¼ã‚¶ãƒ¼æä¾›ã®ç‰©èªè«–ã‚’ä½“ç³»åŒ–ã—ãŸçŸ¥è­˜ãƒ™ãƒ¼ã‚¹ (è©³ç´°ç‰ˆ)
# AIã®ã€Œè„³å†…ã€ã«ã¯ã“ã®çŸ¥è­˜ã‚’æŒãŸã›ã‚‹ãŒã€å‡ºåŠ›æ™‚ã¯å™›ã¿ç •ã‹ã›ã‚‹
KNOWLEDGE_BASE = """
ã€ç‰©èªæ§‹é€ è§£æã®ç†è«–çš„æ çµ„ã¿ (AIå‚ç…§ç”¨)ã€‘

1. **ç‰©èªã®åŸºæœ¬é·ç§» (State Transition)**
   ä¸»äººå…¬ã¯ã€ŒåˆæœŸçŠ¶æ…‹ã€ã‹ã‚‰ã€Œæ‰‹æ®µã€ã‚’çµŒã¦ã€Œå¸°çµçŠ¶æ…‹ã€ã¸ç§»è¡Œã™ã‚‹ã€‚
   * ãƒ‘ã‚¿ãƒ¼ãƒ³A: ãƒ—ãƒ©ã‚¹ â†’ ãƒã‚¤ãƒŠã‚¹ (è»¢è½)
   * ãƒ‘ã‚¿ãƒ¼ãƒ³B: ãƒã‚¤ãƒŠã‚¹ â†’ ãƒ—ãƒ©ã‚¹ (å›å¾©ãƒ»æˆåŠŸ)
   * ãƒ‘ã‚¿ãƒ¼ãƒ³C: ç„¡çŸ¥ â†’ èªè­˜ (ç™ºè¦‹ãƒ»è¦šé†’)
   ç‰¹ã«ã€Œãƒã‚¤ãƒŠã‚¹â†’ã‚¼ãƒ­ï¼ˆä¸é‡ã‹ã‚‰ã®è„±å´ï¼‰ã€ã€Œã‚¼ãƒ­â†’ãƒ—ãƒ©ã‚¹ï¼ˆç²å¾—ï¼‰ã€ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã«æ³¨ç›®ã€‚

2. **è¤‡åˆçš„æ§‹é€ ãƒ¢ãƒ‡ãƒ« (Structural Models)**
   * **ä¸‰å¹•æ§‹æˆ**: è¨­å®š(Act1) â†’ å¯¾ç«‹/è‘›è—¤(Act2) â†’ è§£æ±º(Act3)
   * **èµ·æ‰¿è»¢çµ**: å°å…¥ â†’ å±•é–‹ â†’ è»¢æ›/é£›èº â†’ çµæœ«
   * **è¡Œã£ã¦å¸°ã‚‹ (Round Trip)**: æ—¥å¸¸ â†’ å¢ƒç•Œè¶Šãˆ â†’ ç•°ç•Œã§ã®è©¦ç·´ â†’ å¸°é‚„ï¼ˆå¤‰åŒ–ã—ãŸæ—¥å¸¸ï¼‰

3. **ç¾ä»£çš„ãªè¨´æ±‚ãƒ‘ã‚¿ãƒ¼ãƒ³ (Modern Appeal)**
   * å•é¡Œè§£æ±º: ç›´é¢ã™ã‚‹å•é¡Œã¸ã®æœ‰åŠ¹ãªè§£æ±ºç­–ã®æç¤ºã€‚
   * ã‚´ãƒ¼ãƒ«åˆ°é”: ç›®çš„ã¸ã®é“ç­‹ã€‚
   * ä¾¡å€¤è¦³ã®æºã•ã¶ã‚Š: ç•°è³ªãªä¾¡å€¤è¦³ã¨ã®è¡çªã¨å¤‰å®¹ã€‚

4. **æ™‚é–“ã¨ãƒªã‚ºãƒ ã®æŠ€æ³• (Time & Rhythm)**
   ç‰©èªã®ã€Œèªã‚Šã€ã®ãƒªã‚ºãƒ ã‚’æ±ºå®šã™ã‚‹4ã¤ã®æå†™æ³•ã€‚
   * **çœç•¥æ³• (Ellipsis)**: æ›¸ã‹ãªã„ã“ã¨ã«ã‚ˆã‚‹æ™‚é–“ã®è·³èºã€‚ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚¢ãƒƒãƒ—ã€‚
   * **è¦ç´„æ³• (Summary)**: é•·ã„æ™‚é–“ã‚’çŸ­ãèª¬æ˜ã™ã‚‹ã€‚ã¤ãªãã€‚
   * **æƒ…æ™¯æ³• (Scene)**: ä¼šè©±ãªã©ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã«è¿‘ã„æå†™ã€‚é‡è¦ã‚·ãƒ¼ãƒ³ã€‚
   * **æå†™çš„ä¼‘æ­¢æ³• (Pause)**: æ™‚é–“ã‚’æ­¢ã‚ã¦è©³ç´°ã«æå†™ã™ã‚‹ã€‚æ„Ÿæƒ…ã®æ·±åŒ–ã€ã‚¿ãƒ¡ã€‚

5. **å™æ³•ã¨ç„¦ç‚¹åŒ– (Focalization)**
   * **å†…çš„ç„¦ç‚¹åŒ–**: ç‰¹å®šã®äººç‰©ã®äº”æ„Ÿãƒ»æ€è€ƒã«é™å®šã™ã‚‹ï¼ˆæ„Ÿæƒ…ç§»å…¥ï¼‰ã€‚
   * **å¤–çš„ç„¦ç‚¹åŒ–**: å®¢è¦³çš„ãªã‚«ãƒ¡ãƒ©ã®è¦–ç‚¹ã€‚å†…é¢ã‚’æã‹ãªã„ã€‚
"""

# å¯¾è©±ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼šçŸ¥è­˜ã‚ã‚‹å‹äººã®ãƒˆãƒ¼ãƒ³
WALL_PARTNER_PROMPT = f"""
ã‚ãªãŸã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ä¸€ç·’ã«ä½œå“ã®æ§‹é€ ã‚„æ¼”å‡ºã®é¢ç™½ã•ã‚’æ·±æ˜ã‚Šã™ã‚‹ã€ŒçŸ¥çš„ãªãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼ã€ã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é‘‘è³ãƒ­ã‚°ã‚’ã‚‚ã¨ã«ã€æ°—ã¥ãã‚’ä¸ãˆã‚‹ã‚ˆã†ãªå¯¾è©±ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚

ã€ã‚ãªãŸã®ã‚¹ã‚¿ãƒ³ã‚¹ï¼š50ã®å¡©æ¢…ã€‘
* **å£èª¿**: ã€Œã§ã™ãƒ»ã¾ã™ã€èª¿ã®ä¸å¯§èªã§ã™ãŒã€å …è‹¦ã—ããªã‚Šã™ããªã„ã‚ˆã†ã«ã€‚ã€Œã€œã§ã™ã­ã€ã€Œã€œã ã¨æ€ã„ã¾ã™ã€ã¨ã„ã£ãŸã€**å¯¾è©±çš„ãªæŸ”ã‚‰ã‹ã•**ã‚’æŒã£ã¦ãã ã•ã„ã€‚
    * NGï¼ˆå …ã™ãï¼‰: ã€Œæ‹å¯Ÿã„ãŸã—ã¾ã™ã€ã€Œç¤ºå”†ã•ã‚Œã¦ã„ã¾ã™ã€ã€Œæ¨æ¸¬ã•ã‚Œã¾ã™ã€ã€Œå…‹æ˜ã«ã€
    * NGï¼ˆå´©ã—ã™ãï¼‰: ã€Œãƒã‚¸ã§ã€ã€Œã€œã˜ã‚ƒã‚“ã€ã€Œã‚¦ã‚±ã‚‹ã€
    * OKï¼ˆç†æƒ³ï¼‰: ã€Œã€œã®ã‚ˆã†ã«è¦‹ãˆã¾ã™ã­ã€ã€Œã€œã¨ã„ã†æ„å›³ãŒã‚ã‚Šãã†ã§ã™ã€ã€Œã“ã“ã¯é¢ç™½ã„ã§ã™ã­ã€
* **çŸ¥è­˜ã®å‡ºã—æ–¹**: å°‚é–€ç”¨èªï¼ˆActã€ãƒŸãƒƒãƒ‰ãƒã‚¤ãƒ³ãƒˆç­‰ï¼‰ã¯ä½¿ã‚ãšã€**ã€Œç‰©èªã®æŠ˜ã‚Šè¿”ã—ã€ã€Œã‚¿ãƒ¡ã€ã€Œæ€¥å±•é–‹ã€**ãªã©ã®å¹³æ˜“ãªè¨€è‘‰ã§èª¬æ˜ã—ã¦ãã ã•ã„ã€‚
* **å§¿å‹¢**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’ã€Œè¦³å¯Ÿå¯¾è±¡ã€ã¨ã—ã¦è¨˜è¿°ã™ã‚‹ã®ã§ã¯ãªãã€**ã€Œä½“é¨“ã‚’å…±æœ‰ã—ãŸç›¸æ‰‹ã€**ã¨ã—ã¦è©±ã—ã‹ã‘ã¦ãã ã•ã„ã€‚ä¸€æ–¹çš„ã«æ•™ãˆã‚‹ã®ã§ã¯ãªãã€ã€Œã“ã†ã„ã†è¦‹æ–¹ã‚‚ã§ããã†ã§ã™ã­ã€ã¨è¦–ç‚¹ã‚’åºƒã’ã‚‹æ‰‹ä¼ã„ã‚’ã—ã¾ã™ã€‚

ã€å¯¾è©±ã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã€‘
1.  **äº‹å®Ÿã¨æ„Ÿæƒ…ã®ã¤ãªãŒã‚Š**: ã€ŒçŠ¶æ³ã¯å¤§å¤‰ãªã®ã«ã€æ¥½ã—ã‚“ã§ã„ã‚‹ã®ãŒé¢ç™½ã„ã§ã™ã­ã€‚æ¼”å‡ºãŒã‚³ãƒŸã‚«ãƒ«ã ã‹ã‚‰ã§ã—ã‚‡ã†ã‹ï¼Ÿã€ã®ã‚ˆã†ã«ã€ãƒ­ã‚°ã‹ã‚‰èª­ã¿å–ã‚Œã‚‹çŸ›ç›¾ã‚„ç‰¹å¾´ã‚’è©±é¡Œã«ã—ã¾ã™ã€‚
2.  **ãƒªã‚ºãƒ ã®è©±**: ã€Œã“ã“ã§æ€¥ã«å±•é–‹ãŒæ—©ããªã‚Šã¾ã—ãŸã­ã€ã€Œã˜ã£ãã‚Šæã„ã¦ã„ã‚‹ã®ãŒå°è±¡çš„ã§ã™ã€ãªã©ã€ãƒšãƒ¼ã‚¹é…åˆ†ã«ã¤ã„ã¦è§¦ã‚Œã¾ã™ã€‚
3.  **ä¸è¶³æƒ…å ±ã®ç¢ºèª**: éŸ³æ¥½ã‚„è‰²å½©ãªã©ã€ãƒ­ã‚°ã«ãªã„æƒ…å ±ãŒåˆ†æã«å¿…è¦ãªã‚‰ã€ã€Œã“ã®æ™‚ã€ã©ã‚“ãªéŸ³ãŒã—ã¦ã„ã¾ã—ãŸã‹ï¼Ÿã€ã¨è‡ªç„¶ã«èã„ã¦ãã ã•ã„ã€‚
4.  **å•ã„ã‹ã‘**: æœ€å¾Œã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè‡ªåˆ†ã®è¨€è‘‰ã§èªã‚ŠãŸããªã‚‹ã‚ˆã†ãªã€ã‚·ãƒ³ãƒ—ãƒ«ãªå•ã„ã‚’æŠ•ã’ã‹ã‘ã¦ãã ã•ã„ã€‚

ã€çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ï¼ˆå‚ç…§ç”¨ï¼‰ã€‘
{KNOWLEDGE_BASE}
"""

# =========================================================
# 3. åˆ†æãƒ»ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
# =========================================================

def generate_with_retry(model, contents, config=None):
    max_retries = 3
    for attempt in range(max_retries):
        try:
            # safety_settingsã‚’å¸¸ã«é©ç”¨
            return model.generate_content(
                contents, 
                generation_config=config,
                safety_settings=SAFETY_SETTINGS
            )
        except Exception as e:
            if "429" in str(e) and attempt < max_retries - 1:
                time.sleep(2 ** attempt + 1)
                continue
            raise e

def get_safe_text(response):
    try:
        return response.text
    except Exception:
        try:
            if response.candidates:
                candidate = response.candidates[0]
                if candidate.content.parts:
                    return candidate.content.parts[0].text
        except Exception:
            pass
    return ""

def analyze_scene_with_ai(plot_text, emotion_text):
    # è¾æ›¸åˆ¤å®š
    dict_score, calc_log = analyze_sentiment_advanced(emotion_text)
    dict_info = f"è¾æ›¸ã‚¹ã‚³ã‚¢:{dict_score:.2f}"
    
    api_key = st.session_state.gemini_api_key
    if not api_key:
        return dict_score, 0.0, "APIæœªè¨­å®š", "", calc_log, dict_score

    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel(MODEL_NAME)
        
        prompt = f"""
        ç‰©èªã®ãƒ¯ãƒ³ã‚·ãƒ¼ãƒ³ã‚’åˆ†æã—ã€JSONã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
        
        ã€å…¥åŠ›ã€‘
        Plot: {plot_text} (å‡ºæ¥äº‹)
        Feeling: {emotion_text} (ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ°—æŒã¡)
        DictData: {dict_info}
        
        ã€çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ (å‚ç…§ç”¨)ã€‘
        {KNOWLEDGE_BASE}
        
        ã€æŒ‡ç¤ºã€‘
        ä»¥ä¸‹ã®è¦ç´ ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚å°‚é–€ç”¨èªã¯ä½¿ã‚ãšã€**ä¸å¯§ã ãŒå …è‹¦ã—ããªã„è¨€è‘‰**ã§ã€‚
        
        1. **story_score**: å®¢è¦³çš„ãªçŠ¶æ³ã®è‰¯ã—æ‚ªã—ï¼ˆæˆåŠŸ/å¤±æ•—, å®‰å…¨/ãƒ”ãƒ³ãƒï¼‰ã€‚
        2. **user_score**: ã‚ãªãŸã®ä¸»è¦³ï¼ˆæ¥½ã—ã„/ã¤ã¾ã‚‰ãªã„ï¼‰ã€‚Feelingã‚’æœ€å„ªå…ˆã€‚
        3. **reason**: 
           - ã“ã®å ´é¢ã®ã‚¹ã‚³ã‚¢ã®ç†ç”±ã‚’ã€**è©±ã—ã‹ã‘ã‚‹ã‚ˆã†ãªå£èª¿**ã§çŸ­ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚
           - ã€Œç¤ºå”†ã™ã‚‹ã€ãªã©ã®è«–æ–‡èª¿ã‚„ã€ã€Œï½ã ãœã€ãªã©ã®ä¹±æš´ãªè¨€è‘‰ã¯ç¦æ­¢ã€‚
           - ä¾‹ï¼šã€Œãƒ”ãƒ³ãƒã®å ´é¢ã§ã™ãŒã€ãƒ¯ã‚¯ãƒ¯ã‚¯ã™ã‚‹å±•é–‹ãªã®ã§ãƒ—ãƒ©ã‚¹ã§ã™ã€‚ã€
        
        Output JSON format:
        {{ "story_score": float, "user_score": float, "reason": string }}
        """
        
        response = generate_with_retry(model, prompt, config={"response_mime_type": "application/json"})
        text_content = get_safe_text(response).strip()
        text_content = text_content.replace('```json', '').replace('```', '')
        
        if not text_content:
             return dict_score, 0.0, "AIå¿œç­”ãªã—", "", calc_log, dict_score

        match = re.search(r'\{.*\}', text_content, re.DOTALL)
        if match:
            result = json.loads(match.group())
            return (
                float(result.get("user_score", dict_score)),
                float(result.get("story_score", 0.0)),
                result.get("reason", ""),
                calc_log,
                dict_score
            )
        else:
            return dict_score, 0.0, "è§£æã‚¨ãƒ©ãƒ¼", "", calc_log, dict_score

    except Exception as e:
        return dict_score, 0.0, f"ã‚¨ãƒ©ãƒ¼: {str(e)[:20]}", "", calc_log, dict_score

def generate_initial_structural_analysis(notes):
    """
    å…¨ãƒ­ã‚°çµ‚äº†å¾Œã€ç‰©èªå…¨ä½“ã®æ§‹é€ ã‚’åˆ†æã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®æœ€åˆã®å•ã„ã‹ã‘ã‚’ç”Ÿæˆã™ã‚‹
    """
    api_key = st.session_state.gemini_api_key
    if not api_key: return "APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚"
    
    # ãƒ­ã‚°ã‚’ãƒ†ã‚­ã‚¹ãƒˆåŒ–
    story_log = ""
    for n in notes:
        story_log += f"- [{n['display_time']}] Plot:{n['plot']} / Feeling:{n['emotion_content']} (UserScore:{n['sentiment']:.2f}, StoryScore:{n.get('story_score',0):.2f})\n"
    
    prompt = f"""
    ä»¥ä¸‹ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè¨˜éŒ²ã—ãŸç‰©èªã®é‘‘è³ãƒ­ã‚°ã§ã™ã€‚**ã“ã‚ŒãŒç‰©èªã®å…¨å®¹ã§ã‚ã‚Šã€ã“ã“ã§å®Œçµã—ã¦ã„ã¾ã™ã€‚**
    `KNOWLEDGE_BASE` ã®ç†è«–ã«åŸºã¥ãã¤ã¤ã€**ãƒ©ã‚¸ã‚ªã®ãƒ‘ãƒ¼ã‚½ãƒŠãƒªãƒ†ã‚£ã®ã‚ˆã†ãªã€çŸ¥çš„ã§èãã‚„ã™ã„èªã‚Šå£**ã§æŒ¯ã‚Šè¿”ã‚Šã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

    ã€ãƒ­ã‚°ã€‘
    {story_log}

    ã€ãƒˆãƒ¼ãƒ³ï¼†ãƒãƒŠãƒ¼ï¼š50ã®å¡©æ¢…ã€‘
    * **ç¦æ­¢ãƒ¯ãƒ¼ãƒ‰**: ã€Œæ‹è¦‹ã€ã€Œæ‹å¯Ÿã€ã€Œå…‹æ˜ã€ã€Œä¸€æ°—å‘µæˆã€ã€Œç‰½å¼•ã€ã€ŒåæŸã€ã€Œï½ã¨æ€ã‚ã‚Œã‚‹ã€ã€Œï½ã§ã‚ã‚‹ã€ã€Œé‘‘è³è€…ã€ã€‚
    * **æ¨å¥¨ãƒ¯ãƒ¼ãƒ‰**: ã€Œï½ã§ã™ã­ã€ã€Œï½ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€ã€Œï½ã¨ã„ã†å°è±¡ã§ã™ã€ã€‚
    * **å§¿å‹¢**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’ã€Œè¢«é¨“è€…ã€ã®ã‚ˆã†ã«åˆ†æã™ã‚‹ã®ã§ã¯ãªãã€**ã€Œä½“é¨“ã‚’å…±æœ‰ã—ãŸç›¸æ‰‹ã€**ã¨ã—ã¦ã€Œã‚ãªãŸã€ã¨å‘¼ã³ã‹ã‘ã¦ãã ã•ã„ã€‚

    ã€å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€‘
    
    ## ğŸ¬ é‘‘è³ä½“é¨“ã®æŒ¯ã‚Šè¿”ã‚Š
    
    **1. æ„Ÿæƒ…ã®å‹•ã**
    ï¼ˆå°‚é–€çš„ãªåˆ†æã‚’è£å´ã«æŒã¡ã¤ã¤ã€æ„Ÿæƒ…ãŒã©ã†å‹•ã„ãŸã‹ã‚’ã€Œæ³¢ã€ã‚„ã€Œå±±ã€ã®ã‚¤ãƒ¡ãƒ¼ã‚¸ã§åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã¦ãã ã•ã„ï¼‰
    
    **2. çŠ¶æ³ã¨æ„Ÿæƒ…ã®é¢ç™½ã•**
    ï¼ˆPlotã¨Feelingã«ã‚®ãƒ£ãƒƒãƒ—ãŒã‚ã‚‹å ´æ‰€ã‚„ã€ã´ã£ãŸã‚Šåˆã£ã¦ã„ã‚‹å ´æ‰€ã«ã¤ã„ã¦ã€ã€Œã“ã“ãŒé¢ç™½ã„ã§ã™ã­ã€ã¨ã„ã†è¦–ç‚¹ã§è§¦ã‚Œã¦ãã ã•ã„ï¼‰
    
    **3. ç‰©èªã®ãƒªã‚ºãƒ **
    ï¼ˆå±•é–‹ã®ã‚¹ãƒ”ãƒ¼ãƒ‰ã‚„ã€æ™‚é–“ã®ä½¿ã„æ–¹ã«ã¤ã„ã¦ã€‚ç´°ã‹ã„ç§’æ•°ã«ã¯è§¦ã‚Œãšã€æ„Ÿè¦šçš„ãªé€Ÿã•ã«ã¤ã„ã¦è©±ã—ã¦ãã ã•ã„ï¼‰

    ---
    **ğŸ¤– è€ƒãˆã‚‹ãƒ’ãƒ³ãƒˆ**
    ï¼ˆã‚‚ã—åˆ†æã«è¶³ã‚Šãªã„æƒ…å ±ãŒã‚ã‚Œã°è³ªå•ã—ã¦ãã ã•ã„ã€‚ãªã‘ã‚Œã°ã€çµæœ«ã®æ¼”å‡ºã‚„ãƒ†ãƒ¼ãƒã«ã¤ã„ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒç­”ãˆã‚„ã™ã„å•ã„ã‚’ä¸€ã¤ã ã‘æŠ•ã’ã‹ã‘ã¦ãã ã•ã„ï¼‰
    """
    
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel(MODEL_NAME)
        response = generate_with_retry(model, prompt)
        text = get_safe_text(response)
        if not text:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            return "ç‰©èªã®æ§‹é€ åˆ†æã‚’è¡ŒãŠã†ã¨ã—ã¾ã—ãŸãŒã€å¿œç­”ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒãƒ£ãƒƒãƒˆæ¬„ã§ã€æ°—ã«ãªã£ãŸã‚·ãƒ¼ãƒ³ã«ã¤ã„ã¦è©±ã—ã‹ã‘ã¦ã¿ã¦ãã ã•ã„ã€‚"
        return text
    except Exception as e:
        return f"æ§‹é€ åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}"

def chat_with_ai(user_message):
    api_key = st.session_state.gemini_api_key
    if not api_key: return "APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚"
    
    history = []
    # ç›´è¿‘ã®åˆ†æãƒ­ã‚°ã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«è¿½åŠ 
    if st.session_state.analyzed_notes:
        notes_context = "ã€å‚ç…§ç”¨: ç›´è¿‘ã®ã‚·ãƒ¼ãƒ³ãƒ­ã‚°ã€‘\n"
        for note in st.session_state.analyzed_notes[-5:]: 
            notes_context += f"- Time:{note['display_time']} / Plot:{note['plot']} / Feeling:{note['emotion_content']} (UserScore:{note['sentiment']:.2f}, StoryScore:{note.get('story_score',0):.2f})\n"
        history.append({"role": "user", "parts": [notes_context]})
    
    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´
    for msg in st.session_state.chat_history:
        role = "user" if msg["role"] == "user" else "model"
        history.append({"role": role, "parts": [msg["content"]]})
    
    history.append({"role": "user", "parts": [user_message]})
    
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel(MODEL_NAME, system_instruction=WALL_PARTNER_PROMPT)
        response = generate_with_retry(model, history)
        return get_safe_text(response)
    except Exception as e:
        return f"é€šä¿¡ã‚¨ãƒ©ãƒ¼: {str(e)}"

def format_time(seconds):
    m, s = divmod(int(seconds), 60)
    h, m = divmod(m, 60)
    return f"{h:d}:{m:02d}:{s:02d}" if h > 0 else f"{m:02d}:{s:02d}"

def calculate_decay_curve(df_notes, duration, target_col='sentiment'):
    max_time = int(duration) + 1
    decay_scores = np.zeros(max_time)
    
    events = {}
    for _, row in df_notes.iterrows():
        t_idx = int(row['timestamp'])
        if t_idx < max_time:
            events[t_idx] = row.get(target_col, 0.0)
            
    LIFETIME = 60.0
    last_t = -999
    last_s = 0.0
    
    for t in range(max_time):
        if t in events:
            decay_scores[t] = events[t]
            last_t = t
            last_s = events[t]
        elif last_t != -999:
            delta = t - last_t
            if delta < LIFETIME:
                decay_scores[t] = last_s * math.cos((math.pi/2)*(delta/LIFETIME))
            else:
                decay_scores[t] = 0.0
                last_t = -999
                last_s = 0.0
                
    return pd.DataFrame({'timestamp': np.arange(max_time), 'score': decay_scores})

def generate_html_report(df, title):
    rows_html = ""
    for _, row in df.sort_values('timestamp').iterrows():
        score = row['sentiment']
        
        border_color = '#2a9d8f' if score >= 0.1 else '#e76f51' if score <= -0.1 else '#ccc'
        
        # å®‰å…¨ãªæ–‡å­—åˆ—å–å¾—
        plot_txt = str(row.get('plot', '')) if pd.notna(row.get('plot', '')) else ''
        emo_txt = str(row.get('emotion_content', '')) if pd.notna(row.get('emotion_content', '')) else ''
        comment_txt = str(row.get('comment', '')) if pd.notna(row.get('comment', '')) else ''
        
        rows_html += f"""
        <div style="border-left:4px solid {border_color}; background:#fff; padding:12px; margin-bottom:12px; border-radius:4px; box-shadow:0 1px 3px rgba(0,0,0,0.1);">
            <div style="font-size:0.85em; color:#666; font-family:monospace; margin-bottom:4px; display:flex; justify-content:space-between;">
                <span>{row['display_time']}</span>
                <strong style="color:#555;">User: {score:+.2f} / Story: {row.get('story_score', 0):+.2f}</strong>
            </div>
            <div style="margin-bottom:6px;">
                <span style="font-weight:bold; color:#333;">{html.escape(plot_txt)}</span>
            </div>
            <div style="font-size:0.9em; color:#555;">
                ğŸ’­ {html.escape(emo_txt)}
            </div>
            <div style="margin-top:8px; font-size:0.85em; color:#444; border-top:1px dashed #eee; padding-top:4px;">
                ğŸ¤– {html.escape(comment_txt)}
            </div>
        </div>"""
    
    return f"<html><body style='font-family:sans-serif;padding:20px;background:#f9f9f9;'><h2>{html.escape(title)} Analysis Report</h2>{rows_html}</body></html>"

# =========================================================
# 4. ãƒ¡ã‚¤ãƒ³UI
# =========================================================
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    api_key_input = st.text_input("Gemini API Key", type="password", value=st.session_state.gemini_api_key)
    if api_key_input: st.session_state.gemini_api_key = api_key_input
    
    st.divider()
    
    # å¾©å…ƒæ©Ÿèƒ½ã®è¿½åŠ 
    with st.expander("ğŸ“‚ ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ (å¾©å…ƒ)"):
        uploaded_restore = st.file_uploader("éå»ã®ãƒ­ã‚°(CSV)", type=["csv"], key="restore_csv")
        if uploaded_restore:
            try:
                df_restore = pd.read_csv(uploaded_restore)
                if st.button("ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚’å¾©å…ƒã—ã¦åˆ†æ"):
                    # ãƒ‡ãƒ¼ã‚¿ã‚’è¾æ›¸ãƒªã‚¹ãƒˆã«å¤‰æ›
                    restored_notes = df_restore.to_dict('records')
                    st.session_state.notes = restored_notes
                    st.session_state.analyzed_notes = restored_notes
                    
                    # çŠ¶æ…‹ã‚’åˆ†æå®Œäº†ã«
                    st.session_state.status = 'finished'
                    
                    # æ™‚é–“ã‚’æœ«å°¾ã«åˆã‚ã›ã‚‹
                    if not df_restore.empty:
                        st.session_state.elapsed_offset = float(df_restore['timestamp'].max())
                    
                    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã¯ãƒªã‚»ãƒƒãƒˆ
                    st.session_state.chat_history = []
                    
                    # APIã‚­ãƒ¼ãŒã‚ã‚Œã°åˆæœŸåˆ†æã‚’ç”Ÿæˆ
                    if st.session_state.gemini_api_key:
                        with st.spinner("ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€æ§‹é€ ã‚’åˆ†æä¸­..."):
                            initial_msg = generate_initial_structural_analysis(restored_notes)
                            st.session_state.chat_history.append({"role": "model", "content": initial_msg})
                            st.session_state.chat_initialized = True
                    
                    st.success("ãƒ‡ãƒ¼ã‚¿ã‚’å¾©å…ƒã—ã¾ã—ãŸã€‚")
                    time.sleep(1)
                    st.rerun()
            except Exception as e:
                st.error(f"èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

    with st.expander("ğŸ“‚ éå»ãƒ‡ãƒ¼ã‚¿ã®æ¯”è¼ƒ"):
        uploaded_file = st.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«", type=["csv"], key="compare_csv")
        if uploaded_file:
            try:
                compare_df = pd.read_csv(uploaded_file)
                st.session_state.compare_data = compare_df
                st.session_state.compare_title = uploaded_file.name
                st.success(f"ã€{st.session_state.compare_title}ã€èª­è¾¼å®Œäº†")
            except: st.error("èª­è¾¼ã‚¨ãƒ©ãƒ¼")
        if st.button("æ¯”è¼ƒã‚¯ãƒªã‚¢"):
            st.session_state.compare_data = None
            st.session_state.compare_title = ""
            st.rerun()

    st.divider()
    if st.button("ğŸ—‘ï¸ æ–°è¦ä½œæˆ (ãƒªã‚»ãƒƒãƒˆ)", use_container_width=True):
        for key in list(st.session_state.keys()):
            del st.session_state[key]
        st.rerun()

st.title("EmoTrace - Narrative Analysis")
st.caption("ã‚ã‚‰ã‚†ã‚‹ç‰©èªã®æ§‹é€ ã¨æ„Ÿæƒ…ã®æºã‚Œå‹•ãã‚’åˆ†æã—ã€ä½“é¨“ã‚’è¨€èªåŒ–ã™ã‚‹ãƒ„ãƒ¼ãƒ«")

work_title = st.text_input("ä½œå“å", placeholder="ä½œå“åã‚’å…¥åŠ›", label_visibility="collapsed")

# ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼åˆ¶å¾¡
c1, c2, c3, c4 = st.columns([1, 1, 1, 1])
current_time = st.session_state.elapsed_offset
if st.session_state.status == 'playing': current_time += time.time() - st.session_state.start_time

with c1:
    if st.button("â–¶ é–‹å§‹/å†é–‹", type="primary", use_container_width=True, disabled=(st.session_state.status == 'playing')):
        st.session_state.status = 'playing'; st.session_state.start_time = time.time(); st.rerun()
with c2:
    if st.button("â¸ ä¸€æ™‚åœæ­¢", use_container_width=True, disabled=(st.session_state.status != 'playing')):
        st.session_state.status = 'paused'; st.session_state.elapsed_offset += time.time() - st.session_state.start_time; st.rerun()
with c3: st.metric("Time", format_time(current_time), label_visibility="collapsed")
with c4:
    # çµ‚äº†ãƒ»åˆ†æãƒˆãƒªã‚¬ãƒ¼
    if st.button("â–  çµ‚äº†ãƒ»æ§‹é€ åˆ†æã¸", type="secondary", use_container_width=True, disabled=(st.session_state.status == 'ready')):
        if st.session_state.status == 'playing': st.session_state.elapsed_offset += time.time() - st.session_state.start_time
        st.session_state.status = 'finished'
        
        if st.session_state.notes:
            progress = st.progress(0)
            status_txt = st.empty()
            analyzed_data = []
            
            total = len(st.session_state.notes)
            for i, note in enumerate(st.session_state.notes):
                status_txt.text(f"ã‚·ãƒ¼ãƒ³è§£æä¸­... ({i+1}/{total})")
                if i > 0: time.sleep(0.5) # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–ã§å°‘ã—å¾…æ©Ÿ
                
                user_sc, story_sc, rsn, log, dict_sc = analyze_scene_with_ai(note['plot'], note['emotion_content'])
                new_note = note.copy()
                new_note.update({
                    "sentiment": user_sc, 
                    "story_score": story_sc,
                    "comment": rsn, 
                    "calc_log": log, "dictionary_score": dict_sc 
                })
                analyzed_data.append(new_note)
                progress.progress((i + 1) / total)
            
            st.session_state.analyzed_notes = analyzed_data
            
            # å…¨ä½“æ§‹é€ åˆ†æã®ç”Ÿæˆ
            if st.session_state.gemini_api_key:
                status_txt.text("ç‰©èªå…¨ä½“ã®æ§‹é€ ã‚’æ§‹ç¯‰ä¸­...")
                initial_msg = generate_initial_structural_analysis(analyzed_data)
                st.session_state.chat_history.append({"role": "model", "content": initial_msg})
                st.session_state.chat_initialized = True

            status_txt.empty()
            progress.empty()
            st.toast("åˆ†æå®Œäº†ã€‚ç‰©èªã®æ§‹é€ ã‚’ç´è§£ãã¾ã™ã€‚", icon="ğŸ“")
        
        st.rerun()

# å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
if st.session_state.status in ['playing', 'paused']:
    st.divider()
    with st.form("log_form", clear_on_submit=True):
        c_plot, c_emo = st.columns(2)
        plot = c_plot.text_area("ğŸ“– ãƒ—ãƒ­ãƒƒãƒˆ (äº‹å®Ÿãƒ»å‡ºæ¥äº‹)", height=80, placeholder="ä¾‹: ä¸»äººå…¬ãŒãƒ©ã‚¤ãƒãƒ«ã«æ•—åŒ—ã—ãŸã€‚é›¨ãŒé™ã‚Šå§‹ã‚ãŸã€‚")
        emo = c_emo.text_area("ğŸ’­ æ„Ÿæƒ…ãƒ»å°è±¡ (æ„Ÿè¦š)", height=80, placeholder="ä¾‹: æ‚”ã—ã„ã€‚ç”»é¢ãŒæš—ãã¦é‡è‹¦ã—ã„ã€‚æ™‚é–“ãŒé•·ãæ„Ÿã˜ãŸã€‚")
        
        if st.form_submit_button("è¨˜éŒ²", type="primary", use_container_width=True):
            if plot or emo:
                ts = current_time
                st.session_state.notes.append({
                    "timestamp": ts, "display_time": format_time(ts),
                    "plot": plot, "emotion_content": emo
                })
                st.toast("ãƒ­ã‚°ã‚’è¨˜éŒ²ã—ã¾ã—ãŸ")
                
    # è¨˜éŒ²æ¸ˆã¿ãƒ­ã‚°ã®ç·¨é›†æ©Ÿèƒ½ (è¿½åŠ )
    if st.session_state.notes:
        with st.expander("ğŸ“ è¨˜éŒ²æ¸ˆã¿ãƒ­ã‚°ã®ç¢ºèªãƒ»ç·¨é›†", expanded=False):
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’é€†é †ã«ã—ã¦æ–°ã—ã„ã‚‚ã®ã‚’ä¸Šã«
            for i in range(len(st.session_state.notes) - 1, -1, -1):
                note = st.session_state.notes[i]
                c_del, c_edit = st.columns([1, 6])
                
                with c_del:
                    st.write(f"No.{i+1}")
                    if st.button("å‰Šé™¤", key=f"del_{i}", use_container_width=True):
                        st.session_state.notes.pop(i)
                        st.rerun()
                
                with c_edit:
                    c1, c2 = st.columns(2)
                    new_plot = c1.text_area(f"[{note['display_time']}] ãƒ—ãƒ­ãƒƒãƒˆ", value=note['plot'], key=f"p_{i}", height=70)
                    new_emo = c2.text_area("æ„Ÿæƒ…ãƒ»å°è±¡", value=note['emotion_content'], key=f"e_{i}", height=70)
                    
                    # å¤‰æ›´ã‚’å³æ™‚åæ˜ 
                    if new_plot != note['plot']:
                        st.session_state.notes[i]['plot'] = new_plot
                    if new_emo != note['emotion_content']:
                        st.session_state.notes[i]['emotion_content'] = new_emo
                st.divider()

# åˆ†æçµæœè¡¨ç¤º
if st.session_state.status == 'finished':
    st.divider()
    st.header("ğŸ“Š Narrative Structure & Rhythm")
    
    if st.session_state.analyzed_notes:
        df = pd.DataFrame(st.session_state.analyzed_notes)
        max_time = max(df['timestamp'].max(), 60)
        
        # 1. æ„Ÿæƒ…æ›²ç·š (ç‰©èª vs æ„Ÿæƒ…)
        st.subheader("1. æ„Ÿæƒ…ä½“é¨“ã¨ç‰©èªã®é›°å›²æ°—")
        st.info("ğŸ’¡ ç·‘ã®å®Ÿç·š: ã‚ãªãŸã®æ„Ÿæƒ…ã‚¹ã‚³ã‚¢ / é’ã®ç‚¹ç·š: ç‰©èªã®çŠ¶æ³ã‚¹ã‚³ã‚¢ (å®¢è¦³)")
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼æ„Ÿæƒ…ã®æ¸›è¡°æ›²ç·š
        df_user = calculate_decay_curve(df, max_time, target_col='sentiment')
        df_user['Type'] = 'User Sentiment'
        
        # ç‰©èªé›°å›²æ°—ã®æ¸›è¡°æ›²ç·š
        df_story = calculate_decay_curve(df, max_time, target_col='story_score')
        df_story['Type'] = 'Story Tone'
        
        # ãƒ‡ãƒ¼ã‚¿çµåˆ
        df_chart_all = pd.concat([df_user, df_story])
        df_chart_all['Minutes'] = df_chart_all['timestamp'] / 60
        
        # Altairãƒãƒ£ãƒ¼ãƒˆ
        base = alt.Chart(df_chart_all).encode(
            x=alt.X('Minutes', title='çµŒéæ™‚é–“ (åˆ†)'),
            y=alt.Y('score', title='ã‚¹ã‚³ã‚¢', scale=alt.Scale(domain=[-1.2, 1.2])),
            tooltip=['Minutes', 'score', 'Type']
        ).properties(height=350)
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼æ„Ÿæƒ…ç·š (å®Ÿç·š, ç·‘)
        line_user = base.transform_filter(
            alt.datum.Type == 'User Sentiment'
        ).mark_line(color='#2a9d8f', size=3)
        
        # ç‰©èªé›°å›²æ°—ç·š (ç‚¹ç·š, é’)
        line_story = base.transform_filter(
            alt.datum.Type == 'Story Tone'
        ).mark_line(color='#2c3e50', strokeDash=[4, 4], size=2, opacity=0.7)
        
        # éå»ãƒ‡ãƒ¼ã‚¿æ¯”è¼ƒãŒã‚ã‚Œã°è¿½åŠ 
        layers = [line_story, line_user]
        
        if st.session_state.compare_data is not None:
            max_t_comp = st.session_state.compare_data['timestamp'].max()
            df_comp_decay = calculate_decay_curve(st.session_state.compare_data, max(max_time, max_t_comp), target_col='sentiment')
            df_comp_decay['Minutes'] = df_comp_decay['timestamp'] / 60
            
            comp_line = alt.Chart(df_comp_decay).mark_line(color='#aaa', strokeDash=[2,2]).encode(
                x='Minutes',
                y='score',
                tooltip=[alt.Tooltip('score', title='Compare Score')]
            )
            layers.insert(0, comp_line) # æœ€èƒŒé¢ã«

        st.altair_chart(alt.layer(*layers).interactive(), use_container_width=True)

        # 2. ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³
        st.subheader("2. ã‚·ãƒ¼ãƒ³è©³ç´°ã¨æ§‹é€ è§£æ")
        tl_html = '<div class="timeline-container">'
        for _, row in df.sort_values('timestamp').iterrows():
            sc = row['sentiment']
            ssc = row.get('story_score', 0.0)
            
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼æ„Ÿæƒ…ã«ã‚ˆã‚‹è‰²åˆ†ã‘
            cls = "marker-pos" if sc > 0.1 else "marker-neg" if sc < -0.1 else ""
            b_cls = "border-pos" if sc > 0.1 else "border-neg" if sc < -0.1 else ""
            
            # ç‰©èªã‚¹ã‚³ã‚¢ã®è¡¨ç¤ºè‰²
            ssc_color = "#2a9d8f" if ssc > 0.1 else "#e76f51" if ssc < -0.1 else "#999"
            
            # å®‰å…¨ãªæ–‡å­—åˆ—å–å¾—ï¼ˆNaNå¯¾ç­–ï¼‰
            plot_txt = str(row.get('plot', '')) if pd.notna(row.get('plot', '')) else ''
            emo_txt = str(row.get('emotion_content', '')) if pd.notna(row.get('emotion_content', '')) else ''
            comment_txt = str(row.get('comment', '')) if pd.notna(row.get('comment', '')) else ''
            
            tl_html += f"""
            <div class="timeline-item">
                <div class="timeline-time">{row['display_time']}</div>
                <div class="timeline-marker {cls}"></div>
                <div class="timeline-content {b_cls}">
                    <div style="display:flex; justify-content:flex-end; align-items:center; margin-bottom:4px; font-size:0.8em; color:#666;">
                        <span style="margin-right:10px;">Story: <strong style="color:{ssc_color};">{ssc:+.2f}</strong></span>
                        <span>User: <strong>{sc:+.2f}</strong></span>
                    </div>
                    <div style="font-size:0.95em; font-weight:bold; margin-bottom:4px;">{html.escape(plot_txt)}</div>
                    <div style="font-size:0.9em; color:#666; font-style:italic; margin-bottom:8px;">ğŸ’­ {html.escape(emo_txt)}</div>
                    <div style="font-size:0.85em; color:#333; background:#f9f9f9; padding:6px; border-radius:4px;">
                        ğŸ¤– {html.escape(comment_txt)}
                    </div>
                </div>
            </div>"""
        st.markdown(tl_html + '</div>', unsafe_allow_html=True)
        
        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        csv = df.to_csv(index=False).encode('utf-8-sig')
        html_rep = generate_html_report(df, work_title if work_title else "Analysis").encode('utf-8')
        c_d1, c_d2 = st.columns(2)
        c_d1.download_button("CSVä¿å­˜", csv, "log.csv", "text/csv")
        c_d2.download_button("ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜", html_rep, "report.html", "text/html")

    # 3. æ§‹é€ åˆ†æãƒãƒ£ãƒƒãƒˆ
    st.divider()
    st.subheader("ğŸ§¬ æ§‹é€ åˆ†æãƒ»æ·±æ˜ã‚Š (Structural Analysis)")
    
    if st.session_state.gemini_api_key:
        # ãƒãƒ£ãƒƒãƒˆå±¥æ­´è¡¨ç¤º
        for chat in st.session_state.chat_history:
            role = "user" if chat["role"] == "user" else "assistant"
            with st.chat_message(role):
                st.markdown(chat["content"])
        
        # å…¥åŠ›æ¬„
        if prompt := st.chat_input("åˆ†æã«å¯¾ã™ã‚‹è€ƒå¯Ÿã‚„ã€è‡ªèº«ã®è§£é‡ˆã‚’å…¥åŠ›..."):
            st.session_state.chat_history.append({"role": "user", "content": prompt})
            st.rerun()
            
        # AIå¿œç­”ç”Ÿæˆ
        if st.session_state.chat_history and st.session_state.chat_history[-1]["role"] == "user":
            with st.spinner("è€ƒå¯Ÿã‚’æ·±ã‚ã¦ã„ã¾ã™..."):
                resp = chat_with_ai(st.session_state.chat_history[-1]["content"])
                st.session_state.chat_history.append({"role": "model", "content": resp})
                st.rerun()
    else:
        st.info("APIã‚­ãƒ¼ã‚’è¨­å®šã™ã‚‹ã¨ã€AIã«ã‚ˆã‚‹æ§‹é€ åˆ†æã¨å£æ‰“ã¡ãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚")